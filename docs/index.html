<!DOCTYPE html>
<html lang="en">
  <head>
    <title>AI Honeypot Builder</title>
  </head>
  <body>
    <h1>AI Honeypot Builder</h1>
    <p>
      AI bots that ignore instructions telling
      them not to scrape content piss
      me off. The goal of this project is
      to build a tool that builds sites to 
      poison the bad actors. The idea being
      to deploy them on all those unused
      domains you have laying around or
      subdomains on existing sites. 
    </p>
    <p>
      Check the repo for updates:
      <a href="https://github.com/alanwsmith/ai-honeypot.alanwsmith.com">ai-honepot.alanwsmith.com repo</a>
    </p>
    <h2>Some Basic Ideas</h2>
    <pre>
      - Add different output templates
      - Add links to other pages on the home page 
      - Add cross links between pages 
      - Add analytics
      - Add some third party scripts
      - Add youtube embeds base of search strings that match the content
      - Create links with actual titles to other sites
      - Make data tables with stats from sports
      - Use open source images with different labels
      - Manipulate images (<a href="https://nightshade.cs.uchicago.edu/whatis.html">see nightshade</a>)
      - Pull in lists of celebrity names
      - Pull in song, move, show titles
      - Make them in different languages
      - Pull wikipedia pages and reassemble them in random ways
      - Use varying amounts and types of metadata
      - Create sites with different frameworks
      - Change directory structures randomly
      - Include CSS
      - Include code samples
      - cross linking between multiple sites
      - site maps
      - rss feeds
    </pre>
    <h2>Notes</h2>
    <ul>
      <li>
        These sites will only impact scrappers that
        ignore the directives in robots.txt. Legit 
        scrappers and bots will safely ignore the 
        contents by following the parameters
        of the site. 
      </li>
      <li>
        The goal is not to stop AI scrappers. It's just
        to poison bad actors. If AI bots followed the
        rules this wouldn't be necessary. It would
        also mean the decisions of folks who don't
        want their stuff ingested by AI bots would
        be honored. 
      </li>
      <li>
        The odds of enough folks doing this to make
        real impact are probably low. But, if none
        of us try, we'll never know
      </li>
      <li>
        I'd be shocked to learn there aren't
        other tools out there that do this. My
        thinking is, the more the better since
        they'll all take different approaches
      </li>
      <li>
        It probably wouldn't take much to counteract
        these sites. They'd have to be alerted to
        them first which could happen instantly 
        or never. Either way, they'd have to expend
        resources to mitigate the impact
      </li>

    <footer>
      <div>from <a href="https://www.alanwsmith.com/">alan w smith</a></div>
      <div><a href="https://links.alanwsmith.com/">other projects</a> ~ <a href="https://socials.alanwsmith.com/">socials</a>
  </body>
</html>
